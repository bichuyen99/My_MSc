{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "791ce8e2-0e36-450f-a3d5-85658bd6de24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install torch torchvision gdown -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbd7d285-61b0-4059-945b-e8761759725d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gdown\n",
    "import os\n",
    "from PIL import Image\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "\n",
    "import random\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "353b60a5-4d08-4c2d-8d31-9f2ea7a3d9d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04b2e22-9ecd-41ad-8f2b-36143f7968c0",
   "metadata": {},
   "source": [
    "### Multi-class probplem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d8f5ffc-4586-4244-8786-c279f02476f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdown.download(\"https://drive.google.com/file/d/1q8Jc3LyQfNxuzAAvIQFAcwrgliHRijix/view?usp=share_link\",\"./class_data.zip\", quiet=False, fuzzy=True)\n",
    "!unzip -q ./class_data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b8e8a3-7b84-41a4-a4a0-504de3479100",
   "metadata": {},
   "source": [
    "### Resnet training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a33356ce-125b-4587-a725-203fd63a5235",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('multi_class_output'):\n",
    "    os.mkdir('multi_class_output')\n",
    "else:\n",
    "    print('multi_class_output exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53450e48-2a50-490b-8dab-ef8db32bb9b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May 21 19:02:18 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.105.01   Driver Version: 515.105.01   CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:41:00.0 Off |                  N/A |\n",
      "|  0%   40C    P2   149W / 370W |   7166MiB / 24576MiB |     27%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:61:00.0 Off |                  N/A |\n",
      "|  0%   37C    P2   145W / 370W |   6353MiB / 24576MiB |     27%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce ...  Off  | 00000000:A1:00.0 Off |                  N/A |\n",
      "|  0%   40C    P2   149W / 370W |   6575MiB / 24576MiB |     30%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce ...  Off  | 00000000:E1:00.0 Off |                  N/A |\n",
      "|  0%   34C    P2   140W / 370W |   6459MiB / 24576MiB |     28%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6980a321-0db4-4017-9a37-e7d4cb8f2780",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7c088bf-c55e-42ba-9d30-dc0ec85225b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b1a1c42-7247-4692-8cc1-e620a0a8512b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIABLE_DEVICES']='0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30edafdf-6845-4446-aed5-0d0008e8e56e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e952232-ad01-4dad-8685-2fc83010c2a7",
   "metadata": {},
   "source": [
    "### VIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b134addb-469a-4110-8c12-deecc9e8fd10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformer.vit import Transformer\n",
    "from utils.trainer import Trainer\n",
    "from data.multi_class_build_data import build_dataloader\n",
    "\n",
    "BATCH_SIZE=8\n",
    "\n",
    "transfrom = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.5, 0.5)\n",
    "])\n",
    "\n",
    "train_dataloader, test_dataloader, trainset_len, testset_len, NUM_CLASS = build_dataloader(transfrom, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53055a26-6025-4b07-9b99-a04d9335a712",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "criteriation=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dc0ce50b-9051-436b-b627-22359ace3f90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transformer = Transformer(img_size=(240, 320),\n",
    "                          patch_size=(8, 8),\n",
    "                          in_channels=3,\n",
    "                          n_classes=NUM_CLASS,\n",
    "                          embed_dim=128,\n",
    "                          depth=6,\n",
    "                          n_heads=16,\n",
    "                          mlp_ratio=4.,\n",
    "                          qkv_bias=True,\n",
    "                          p=0.3,\n",
    "                          attn_p=0.3\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "458e6c90-811c-4606-95ff-20046af388d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transformer = transformer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "baea5822-4efa-4e93-9023-b479d2edeae9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d1c881-c007-4f1b-8382-ae2470a3a02a",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "db05f3b9-db4b-4597-8a2b-9dcb0bab5f7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NAME = 'vit'\n",
    "\n",
    "trainer = Trainer(transformer , \n",
    "                  criteriation,\n",
    "                  device,\n",
    "                  train_dataloader,\n",
    "                  test_dataloader,\n",
    "                  trainset_len,\n",
    "                  testset_len,\n",
    "                  optimizer,\n",
    "                  epochs=2,\n",
    "                  path_output='multi_class_output/{name}.pt'.format(name=NAME),\n",
    "                  multi_label=False\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "92089531-75f8-45d1-b960-3271fb067f9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]/[2] Epoch starts\n",
      "\t Batch train loss: 1.2611844539642334, accuracy 0.5\n",
      "\t Batch train loss: 1.3615361452102661, accuracy 0.25\n",
      "\t Batch train loss: 1.3960784673690796, accuracy 0.25\n",
      "\t Batch train loss: 1.382154107093811, accuracy 0.375\n",
      "\t Batch train loss: 1.396828055381775, accuracy 0.125\n",
      "[1]/[2] End epoch: train loss: 1.388670197976597, val loss: 1.4063543627240067\n",
      "\t Epoch train accuracy: 0.25851160287857056, val accuracy: 0.24929634097305992\n",
      "\n",
      "[2]/[2] Epoch starts\n",
      "\t Batch train loss: 1.4980098009109497, accuracy 0.125\n",
      "\t Batch train loss: 1.4070000648498535, accuracy 0.125\n",
      "\t Batch train loss: 1.1671994924545288, accuracy 0.625\n",
      "\t Batch train loss: 1.50556480884552, accuracy 0.25\n",
      "\t Batch train loss: 1.5396944284439087, accuracy 0.25\n",
      "[2]/[2] End epoch: train loss: 1.3361544116045967, val loss: 1.3421580781407465\n",
      "\t Epoch train accuracy: 0.3368484377861023, val accuracy: 0.3606755126658625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.training()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9c9a2d-e919-4444-8b70-cc6bb554c165",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1383de9b-b784-4fd7-b4fc-0404ebd7bcb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save cuda memory\n",
    "# culd skip\n",
    "\n",
    "del transformer\n",
    "\n",
    "\n",
    "transformer = Transformer(img_size=(240, 320),\n",
    "                          patch_size=(8, 8),\n",
    "                          in_channels=3,\n",
    "                          n_classes=NUM_CLASS,\n",
    "                          embed_dim=128,\n",
    "                          depth=6,\n",
    "                          n_heads=16,\n",
    "                          mlp_ratio=4.,\n",
    "                          qkv_bias=True,\n",
    "                          p=0.3,\n",
    "                          attn_p=0.3\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f855a594-54e2-4dc7-b6fd-bc791a7b39eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transformer.load_state_dict(torch.load(f'multi_class_output/vit.pt')['model_state_dict'])\n",
    "transformer = transformer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cb895a39-fd71-4bd5-b145-4d33adbaebfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_, _, preds = trainer.val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b62de6c4-1d0f-4eaa-8f23-d9c296d874a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediciton = pd.DataFrame([preds[0].cpu().numpy(), preds[1].cpu().numpy()]).T\n",
    "prediciton.rename = ['labels', 'predictions']\n",
    "\n",
    "prediciton.to_csv('multi_class_output/{name}.csv'.format(name=NAME), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96382bfd-31aa-4a51-864c-8b4c3505917f",
   "metadata": {},
   "source": [
    "### Multi-label problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b571d1e-b64f-4890-8e7c-b79509639473",
   "metadata": {},
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "be5bc2ae-4021-4ccc-8685-26bb1a365abc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (uriginal): https://drive.google.com/uc?id=15aX9gKeSlGoUJBHAQGqkL5euq0kDKkwg\n",
      "From (redirected): https://drive.google.com/uc?id=15aX9gKeSlGoUJBHAQGqkL5euq0kDKkwg&confirm=t&uuid=e2edee54-c278-4706-a7ab-fe137a692663\n",
      "To: /home/jovyan/work/label_data.zip\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 4.51G/4.51G [00:52<00:00, 86.0MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace sample/images/00000013_005.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
     ]
    }
   ],
   "source": [
    "gdown.download(\"https://drive.google.com/file/d/15aX9gKeSlGoUJBHAQGqkL5euq0kDKkwg/view?usp=share_link\",\"./label_data.zip\", quiet=False, fuzzy=True)\n",
    "!unzip -q ./label_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1d2a83f8-7aab-4efc-9506-075065e2692f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Clean dataset: RUN ONLY ONCE\n",
    "data = pd.read_csv('sample_labels.csv')\n",
    "data['lables'] = data['Finding Labels'].str.split('|')\n",
    "data['Image Index'] = './sample/images/' + data['Image Index']\n",
    "\n",
    "chen = []\n",
    "for path_img in data['Image Index'].values:\n",
    "    img = Image.open(path_img)\n",
    "    chen.append(transforms.ToTensor()(img).shape)\n",
    "\n",
    "bad_img = data.loc[pd.DataFrame(chen)[0] > 1, 'Image Index'].values\n",
    "\n",
    "for path_img in bad_img:\n",
    "    img = plt.imread(path_img)\n",
    "    img = img[:, :, 0]\n",
    "    img = Image.fromarray(np.uint8(img * 255), 'L')\n",
    "    img.save(path_img,\"PNG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bddfe218-cfbc-4c95-903d-31875f208dcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('multi_label_output'):\n",
    "    os.mkdir('multi_label_output')\n",
    "else:\n",
    "    print('multi_label_output exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776bbfb2-8ae9-49ba-82b4-b8b0b01b2aa4",
   "metadata": {},
   "source": [
    "### Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f98564fa-3560-4c92-b78f-f080c901daac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "criteriation = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e015cea8-8927-4d2f-887d-926156ce1896",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.trainer import Trainer\n",
    "from data.multi_label_build_data import build_dataloader\n",
    "\n",
    "BATCH_SIZE=4\n",
    "\n",
    "transfrom = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.5, 0.5)\n",
    "])\n",
    "\n",
    "train_dataloader, test_dataloader, trainset_len, testset_len, NUM_CLASS = build_dataloader(transfrom, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad1e804a-518c-4753-8f05-c91d550a935d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformer.vit import Transformer\n",
    "\n",
    "transformer = Transformer(img_size=(256, 256),\n",
    "                          patch_size=(8, 8),\n",
    "                          in_channels=1,\n",
    "                          n_classes=NUM_CLASS,\n",
    "                          embed_dim=128,\n",
    "                          depth=6,\n",
    "                          n_heads=16,\n",
    "                          mlp_ratio=4.,\n",
    "                          qkv_bias=True,\n",
    "                          p=0.3,\n",
    "                          attn_p=0.3\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "08bac1d1-b6b4-435f-8d87-9c5f21f36819",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = transformer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "42fca761-b6ec-4bb5-a15e-a1335f69b20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fe54a0c9-f461-4299-b9eb-27c524da78f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = 'vit'\n",
    "\n",
    "trainer = Trainer(transformer , \n",
    "                  criteriation,\n",
    "                  device,\n",
    "                  train_dataloader,\n",
    "                  test_dataloader,\n",
    "                  trainset_len,\n",
    "                  testset_len,\n",
    "                  optimizer,\n",
    "                  epochs=2,\n",
    "                  path_output='multi_label_output/{name}.pt'.format(name=NAME),\n",
    "                  multi_label=True\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0ee56368-dde0-4cac-9f45-a013934a1ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]/[2] Epoch starts\n",
      "\t Batch train loss: 0.29011303186416626, accuracy 0.42895299145299143\n",
      "\t Batch train loss: 0.1923581212759018, accuracy 0.6666666666666666\n",
      "\t Batch train loss: 0.16357667744159698, accuracy 0.8\n",
      "\t Batch train loss: 0.49025410413742065, accuracy 0.5884920634920634\n",
      "\t Batch train loss: 0.2088184356689453, accuracy 0.5692307692307692\n",
      "[1]/[2] End epoch: train loss: 0.22505359889538656, val loss: 0.22471263094154667\n",
      "\t Epoch train accuracy: 0.6901891100824052, val accuracy: 0.6822122996688117\n",
      "\n",
      "[2]/[2] Epoch starts\n",
      "\t Batch train loss: 0.10491913557052612, accuracy 1.0\n",
      "\t Batch train loss: 0.15026028454303741, accuracy 0.8125\n",
      "\t Batch train loss: 0.10341835767030716, accuracy 1.0\n",
      "\t Batch train loss: 0.15371689200401306, accuracy 0.7857142857142857\n",
      "\t Batch train loss: 0.12722177803516388, accuracy 0.8333333333333334\n",
      "[2]/[2] End epoch: train loss: 0.21665471261294522, val loss: 0.220863472514127\n",
      "\t Epoch train accuracy: 0.6923170739929381, val accuracy: 0.6831609621752351\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.training()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a05da17-e6d8-43d6-9c0d-dadcf6cd724d",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60f0444e-e086-499d-9ade-5e127b5b830c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transformer.load_state_dict(torch.load(f'multi_label_output/vit.pt')['model_state_dict'])\n",
    "transformer = transformer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66db2f56-f5f1-463a-aa43-b031a51e2359",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(transformer , \n",
    "                  criteriation,\n",
    "                  device,\n",
    "                  train_dataloader,\n",
    "                  test_dataloader,\n",
    "                  trainset_len,\n",
    "                  testset_len,\n",
    "                  path_output='multi_label_output/{name}.pt'.format(name=NAME),\n",
    "                  multi_label=True\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5f27dfa-0456-4dfc-b276-58905da88210",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_, _, preds = trainer.val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4a79b654-c80f-4fb5-b857-db67e7629118",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(preds[0].cpu().numpy()).to_csv('multi_label_output/true_{name}.csv'.format(name=NAME), index=False)\n",
    "pd.DataFrame(preds[1].cpu().numpy()).to_csv('multi_label_output/pred_{name}.csv'.format(name=NAME), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
