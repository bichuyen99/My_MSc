{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from typing import Tuple\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "import time\n",
        "from collections import defaultdict\n",
        "import itertools"
      ],
      "metadata": {
        "id": "R5K0yStAPJQE"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Task 1: Value Iteration </h2>\n",
        "A. Enumerate the action space. The coordinates of actions are u = (row; column)"
      ],
      "metadata": {
        "id": "2Vmxa2dGJ-Dw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this is the set of possible actions admitted in this problem\n",
        "action_space = [(-1, 0), (0, -1), (1, 0), (0, 1)]\n",
        "for index, action in enumerate(action_space):\n",
        "    u_row = action[0]\n",
        "    u_col = action[1]\n",
        "    print(f'u{index}:=({u_row};{u_col})')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgRQNV6WEKVP",
        "outputId": "3badeb96-74b3-4491-a2ab-9bf24c6cf093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "u0:=(-1;0)\n",
            "u1:=(0;-1)\n",
            "u2:=(1;0)\n",
            "u3:=(0;1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "B. Formulate the optimal cost-to-go G∗ in recursive form. Also formulate how to obtain the optimal policy u∗ from G∗."
      ],
      "metadata": {
        "id": "vl63t1eyHcXX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ Formula of the optimal cost-to-go $G^*:$\n",
        "$$G^*_k(x_k)= min(G^*_{k+1}(f(x_k,u_k))+l(x_k,u_k))$$\n",
        "where $l(x_k,u_k)$ - cost of traversing from node $x_k$ to $x_{k+1}$ by action $u_k$.  \\\\\n",
        "For finite length sequences: \n",
        "$$G_F^*(x_F)=l_F(x_F)= \\begin{cases}\n",
        "0 ~~~\\text{ if } x_F \\in X_G \\\\\n",
        "\\infty ~\\text{ if } x_F \\notin X_G\n",
        "\\end{cases} $$ \n",
        "where $x_F$ - final state; $X_G$ - goal space \n",
        "+ Formula of the optimal policy $u^*$ from $G^*:$\n",
        "$$u^* = argmin(G^*(f(x,u))+l(x,u)) $$\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "82GsAPXbWVbi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "C. Implement the VI algorithm for infinite length sequences. To show this, you are asked to include a picture of G∗ after convergence. Attach a video of the animation. The cost of traversing each node l(x; u) = 1 only if propagation is possible (there is not obstacle or out of\n",
        "bounds)."
      ],
      "metadata": {
        "id": "8rWRxQzPYK1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def state_consistency_check(env: np.array, x: Tuple) -> bool:\n",
        "    \"\"\"Checks wether or not the proposed state is a valid state, i.e. is in colision or our of bounds\"\"\"\n",
        "    # check for collision\n",
        "    if x[0] < 0 or x[1] < 0 or x[0] >= env.shape[0] or x[1] >= env.shape[1]:\n",
        "        return False\n",
        "    if env[x] >= 1.0 - 1e-4:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "def pursuer_policy(x_e: Tuple, x_p: Tuple) -> int:\n",
        "    \"\"\"Returns the pursuer action\"\"\"\n",
        "    ds = np.array(x_e) - np.array(x_p)\n",
        "    theta = np.arctan2(ds[1], ds[0])\n",
        "    theta = (theta + np.pi) / np.pi * 2\n",
        "    u_index = np.floor(theta)\n",
        "    delta = theta - u_index\n",
        "    if np.random.rand() < delta:\n",
        "        u_index += 1\n",
        "    if u_index == 4:\n",
        "        u_index = 0  # this is due to action 0  equals action 4 in this particular order of th action space\n",
        "\n",
        "    return int(u_index)\n",
        "\n",
        "def transition_function(env: np.array, x: Tuple, u: Tuple) -> (Tuple, bool):\n",
        "    xnew = np.array(x) + np.array(u)\n",
        "    xnew = tuple(xnew)\n",
        "    if state_consistency_check(env, xnew):\n",
        "        return xnew, True\n",
        "    return x, False"
      ],
      "metadata": {
        "id": "CK-_h6T4cntX"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vi(env: np.array, goal: Tuple) -> Tuple[np.array, np.array]:\n",
        "    policy, cost_to_go = np.zeros(env.shape, 'b'), np.ones(env.shape) * 1e2\n",
        "    cost_to_go[goal] = 0\n",
        "    while True:\n",
        "        is_new = False\n",
        "        for i in range(len(cost_to_go)):\n",
        "            for j in range(len(cost_to_go)):\n",
        "              index = [i,j]\n",
        "              for act_idx, action in enumerate(action_space):\n",
        "                  idx, no_collise = transition_function(env, index , action)\n",
        "                  if no_collise:\n",
        "                      new_cost = 1 + cost_to_go[idx]\n",
        "                      if new_cost < cost_to_go[i,j]:\n",
        "                          is_new = True\n",
        "                          cost_to_go[i,j] = new_cost\n",
        "                          policy[i,j] = act_idx\n",
        "        assert cost_to_go[goal] == 0\n",
        "        if not is_new:\n",
        "            break\n",
        "    return policy, cost_to_go"
      ],
      "metadata": {
        "id": "2uXPOJ4DTM3T"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "pD9jV0yNJHYW"
      },
      "outputs": [],
      "source": [
        "def plot_joint_enviroment(env: np.array, x_e: Tuple, x_p: Tuple, goal: Tuple) -> np.array:\n",
        "    current_env = np.copy(env)\n",
        "    # plot evader\n",
        "    current_env[x_e] = 0.9  # yellow\n",
        "    # plot pursuer\n",
        "    current_env[x_p] = 0.6  # cyan-ish\n",
        "    # plot goal\n",
        "    current_env[goal] = 0.3\n",
        "    return current_env"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.load('/data_ps3.npz')\n",
        "environment = data['environment']\n",
        "# plt.matshow(environment)\n",
        "# (row index, colum index). In the image row corresponds to y, and colum to x.\n",
        "x_e = tuple(data[\"x_e\"])  # (11, 6) you free to use it as np array if you prefer, but utils.py is expecting a tuple\n",
        "x_p = tuple(data[\"x_p\"])  # (7, 25)\n",
        "goal = tuple(data[\"goal\"])  # (15, 29)\n",
        "# task 1 VI for evader\n",
        "# ======================================\n",
        "default_policy, Gopt = vi(environment, goal)\n",
        "# visualize the optimal policy\n",
        "plt.matshow(Gopt)\n",
        "# Visualization\n",
        "# ======================================\n",
        "im = plot_joint_enviroment(environment, x_e, x_p, goal)\n",
        "plt.matshow(im)\n",
        "plt.show()\n",
        "# The Game\n",
        "fig = plt.figure()\n",
        "imgs = []\n",
        "pbar = tqdm(range(100))\n",
        "for s in pbar:\n",
        "    im = plot_joint_enviroment(environment, x_e, x_p, goal)\n",
        "    plot = plt.imshow(im)\n",
        "    imgs.append([plot])\n",
        "    # according to the optimal policy of the evader, move the evader\n",
        "    u_e = action_space[default_policy[x_e]]  # default_policy without taking into account the pursuer\n",
        "    # u_e = mcts(environment, x_e, x_p, goal, 100, default_policy)  # taking into account pursuer, simulating the game\n",
        "    x_e, _ = transition_function(environment, x_e, u_e)\n",
        "    if x_e == goal:\n",
        "        print('WIN!')\n",
        "        break\n",
        "    # propagate the pursuer: TODO uncomment the next line to release the beast\n",
        "    # x_p = pursuer_transition(environment,x_e, x_p)\n",
        "    if x_p == x_e:\n",
        "        print('game over((')\n",
        "        break\n",
        "    pbar.set_description(f'x_e: {x_e}, x_p: {x_p},'\n",
        "                         f' distance to goal: {np.linalg.norm(np.array(x_e) - np.array(goal)):0.2f}'\n",
        "                         f' distance to pursuer: {np.linalg.norm(np.array(x_e) - np.array(x_p)):0.2f}')\n",
        "im = plot_joint_enviroment(environment, x_e, x_p, goal)\n",
        "plot = plt.imshow(im)\n",
        "imgs.append([plot])\n",
        "ani = animation.ArtistAnimation(fig, imgs, interval=100, blit=True)\n",
        "ani.save('/escape_vi.mp4')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "9wOpjOLMOEn0",
        "outputId": "62f77630-5902-40ab-f358-edfa164062f7"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "x_e: (15, 28), x_p: (7, 25), distance to goal: 1.00 distance to pursuer: 8.54:  40%|████      | 40/100 [00:00<00:00, 227.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WIN!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "D. Un-comment the pursuer transition function in line 54. Did you escape?"
      ],
      "metadata": {
        "id": "EA3NlG3hdZT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pursuer_transition(env: np.array, x_e: Tuple, x_p: Tuple) -> Tuple:\n",
        "    \"\"\"\n",
        "    compact function for the transition function and policy for the pursuer\n",
        "    5% is the probability of the pursuer to make a double move\n",
        "\n",
        "    env - enviroment\n",
        "    x_e - evader state\n",
        "    x_p - pursuer state\n",
        "    returns the new state of the pursuer\n",
        "    \"\"\"\n",
        "    iters = 1\n",
        "    if np.random.rand() < 0.05:\n",
        "        iters = 2\n",
        "    for i in range(iters):\n",
        "        u_p = pursuer_policy(x_e, x_p)\n",
        "        x_p, _ = transition_function(env, x_p, action_space[u_p])\n",
        "    return x_p"
      ],
      "metadata": {
        "id": "rkGusp7FdzaU"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (row index, colum index). In the image row corresponds to y, and colum to x.\n",
        "x_e = tuple(data[\"x_e\"])  # (11, 6) you free to use it as np array if you prefer, but utils.py is expecting a tuple\n",
        "x_p = tuple(data[\"x_p\"])  # (7, 25)\n",
        "goal = tuple(data[\"goal\"])  # (15, 29)\n",
        "# task 1 VI for evader\n",
        "# ======================================\n",
        "default_policy, Gopt = vi(environment, goal)\n",
        "# visualize the optimal policy\n",
        "plt.matshow(Gopt)\n",
        "# Visualization\n",
        "# ======================================\n",
        "im = plot_joint_enviroment(environment, x_e, x_p, goal)\n",
        "plt.matshow(im)\n",
        "plt.show()\n",
        "\n",
        "# The Game\n",
        "fig = plt.figure()\n",
        "imgs = []\n",
        "pbar = tqdm(range(100))\n",
        "for s in pbar:\n",
        "    im = plot_joint_enviroment(environment, x_e, x_p, goal)\n",
        "    plot = plt.imshow(im)\n",
        "    imgs.append([plot])\n",
        "    # according to the optimal policy of the evader, move the evader\n",
        "    u_e = action_space[default_policy[x_e]]  # default_policy without taking into account the pursuer\n",
        "    x_e, _ = transition_function(environment, x_e, u_e)\n",
        "    if x_e == goal:\n",
        "        print('WIN!')\n",
        "        break\n",
        "    # propagate the pursuer: TODO uncomment the next line to release the beast\n",
        "    x_p = pursuer_transition(environment,x_e, x_p)\n",
        "    if x_p == x_e:\n",
        "        print('game over((')\n",
        "        break\n",
        "    pbar.set_description(f'x_e: {x_e}, x_p: {x_p},'\n",
        "                         f' distance to goal: {np.linalg.norm(np.array(x_e) - np.array(goal)):0.2f}'\n",
        "                         f' distance to pursuer: {np.linalg.norm(np.array(x_e) - np.array(x_p)):0.2f}')\n",
        "im = plot_joint_enviroment(environment, x_e, x_p, goal)\n",
        "plot = plt.imshow(im)\n",
        "imgs.append([plot])\n",
        "ani = animation.ArtistAnimation(fig, imgs, interval=100, blit=True)\n",
        "ani.save('/escape_vi1.mp4')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "-k7nYQ8LdsJn",
        "outputId": "061fdecd-7f49-41b4-c381-a49a73f54199"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAECCAYAAAD+eGJTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAROklEQVR4nO3db4hddX7H8ffnTv4Yk+gm6xpC1tZWfNBlobEMUlgplqVbuxTUJ7IpLCksjQ9WWGEfVHyiTwpS/NN9UIRYZbPg2grqKlS6K7Jg94nsKEGjabvLEqkhJrqx5o9xMnfutw/umWRmdn6/c3PuzDk3/j4vkMzc3z3nfD0z85l7z/f3O6OIwMzK1eu6ADPrlkPArHAOAbPCOQTMCucQMCucQ8CscJ2EgKTbJP23pF9Luq+LGpaTdETS25IOSprpsI6nJJ2QdGjRY9slvSLpV9W/2yagpgclHa3O10FJ32y5pusk/VzSu5LekfS96vHOzlWmpk7PVR21PU9A0hTwP8BfAO8DvwT2RMS7rRbyu3UdAaYj4qOO6/gz4Azwo4j4avXYPwInI+KhKjS3RcTfd1zTg8CZiHi4rTqW1bQT2BkRb0raCrwB3AH8LR2dq0xNd9HhuarTxSuBm4FfR8RvIuI88K/A7R3UMZEi4jXg5LKHbwcOVB8fYPiN1XVNnYqIYxHxZvXxaeAwsIsOz1WmponWRQjsAv530efvMxknKoCfSXpD0r6ui1lmR0Qcqz7+ANjRZTGL3CPprertQqtvURaTdD1wE/A6E3KultUEE3KuVuILgxfdEhF/AvwV8N3qJfDEieH7t0mY6/04cAOwGzgGPNJFEZK2AM8B90bEqcVjXZ2rFWqaiHOV0kUIHAWuW/T5l6vHOhURR6t/TwAvMHzbMimOV+83F953nui4HiLieETMR8QAeIIOzpek9Qx/2J6OiOerhzs9VyvVNAnnKqeLEPglcKOkP5C0AfgW8FIHdVwgaXN1IQdJm4FvAIfyW7XqJWBv9fFe4MUOawEu/IAtuJOWz5ckAU8ChyPi0UVDnZ2rVE1dn6s6rXcHAKoWyT8BU8BTEfEPrRextJ4/ZPjbH2Ad8OOuapL0DHArcA1wHHgA+AnwLPB7wHvAXRHR2oW6RE23Mnx5G8AR4O5F78XbqOkW4D+Bt4FB9fD9DN+Dd3KuMjXtocNzVaeTEDCzyeELg2aFcwiYFc4hYFY4h4BZ4RwCZoXrNAQmcHquaxqRaxrdpNa1oOtXApN4clzTaFzT6Ca1LqD7EDCzjo01WUjSbcAPGM78+5eIeCj3/Ku2r4trd2248Pmpk32u2r4OgPmaPBqEkmPzkd82t+/l+z338Sybtm0cad8D0jWttO9Rx5aP9z85x7qrN134PC5h2+Xqts1/O1zcdv7UWaau2rzooNnd1izjydeU3XbRcQdnz9LbvHnJcHbPdd/6mXFdwrbzn55l6sqLdV3KtuMcd7HZMyfpf3Z2xdOxrmaX6WKGNwf5ZxbdHETSS7mbg1y7awMP/+TGFcdODzat+PiF8fkrkmOfzF/ZeNsz8xuTYwBn++nxs/0NyTGATzPj5/rrs9vmxs/N5bed7U8lx+bm8l/y/lx62/l+OhBjruZFZWZc/XwIaC493juf37bXz4xl9js8brP9DvfdbGw4nv5Jnzrf7Ljv/vtj6W3yu8zyzUHMPgfGCYFJvTmImV2CNb8wKGmfpBlJM6dO1ryGMrPWjRMCI90cJCL2R8R0REwvXAQ0s8kxzk/lhZuDMPzh/xbwN7kN5uklLwDmLt5B/uJf3ba5i3+5C3/D8fTFvdyFP6i5uFd3YTBz8S934Q/yF/9yF/5gjIt/NRcGcxf/chf+IH/xr/4CXe64NdtmLyrWHTc3lr/En7v4V3fcqcS+c12FxiEQEX1J9wA/5eLNQd5puj8z68ZYr88j4mXg5VWqxcw64BmDZoVzCJgVziFgVjiHgFnhHAJmhWt19s4glOzpexHQUl0sAoLmcwG8CGj5+OovAoL0PIDa42Y28ysBs8I5BMwK5xAwK5xDwKxwDgGzwjkEzArXaotwPnrJVqCXAy/VyXJgaNwG9HLgpdZiOfBox00sJR5k9pkvx8w+7xwCZoVzCJgVziFgVjiHgFnhHAJmhXMImBWu3XkC9JLzAbwceKkulgND87kAXg48+r4bLwcmPQ+gdlsvJTazFIeAWeEcAmaFcwiYFc4hYFY4h4BZ4VptEU4xYOvUZ20eskjzmbF8gwmi4e+FQe0zcm3AmrZXZtv6446jec3N9wvrz6b/r+qWEvfOJ7Zdi79KDCDpCHCa4fddPyKmx9mfmbVvNV4J/HlEfLQK+zGzDviagFnhxg2BAH4m6Q1J+1ajIDNr17hvB26JiKOSrgVekfRfEfHa4idU4bAP4As78/cRNLP2jfVKICKOVv+eAF4Abl7hOfsjYjoipjdvyy/0MbP2NQ4BSZslbV34GPgGcGi1CjOzdozzdmAH8IKkhf38OCL+I7fBlAZcPfXpGIe0ceXmEEC++910DgHU9fPzffNcVbk5BPXHHUfzmuvk5gIk5wFcGF/5K6xI77NxCETEb4A/brq9mU0GtwjNCucQMCucQ8CscA4Bs8I5BMwK1+pS4p7CS4knXNNlyGvXPoTSliHn2oCpFuCCqdnEeOZ/1q8EzArnEDArnEPArHAOAbPCOQTMCucQMCucQ8CscO3fcrx3rs1D2irq4lbmUN4y5NxcgOQ8gIU9n1/5zzTnlhL7lYBZ4RwCZoVzCJgVziFgVjiHgFnhHAJmhWu9RXhVz0uJx7X9ivwdm4+evrqlSi6azLsYw+W4DDnXBky1AGvH3SI0sxSHgFnhHAJmhXMImBXOIWBWOIeAWeEcAmaFq50nIOkp4K+BExHx1eqx7cC/AdcDR4C7IuLjun31FGz1PIGxXbnufHZ895eOJscOfrhrtcsZiZchjy43F6B2nsDs3MoDY84T+CFw27LH7gNejYgbgVerz83sMlQbAhHxGnBy2cO3Aweqjw8Ad6xyXWbWkqavs3ZExLHq4w+AHatUj5m1bOwLgxERZN48SdonaUbSzP+drJthbmZtaxoCxyXtBKj+PZF6YkTsj4jpiJj+wvaphoczs7XSNAReAvZWH+8FXlydcsysbaO0CJ8BbgWukfQ+8ADwEPCspO8A7wF3jXKwKYKtvUQLw0a2uaZFuHndbHLsL798OLvtT9//o0Y1jcPLkJcdNdciTLUAF5xPjA/S9daGQETsSQx9vW5bM5t8njFoVjiHgFnhHAJmhXMImBXOIWBWOIeAWeFavuV4sFWJfqXnD4wsNw8AYMtUevzM/Mbstl6GfFFXy5CzcwFS8wAWjjqbmEPiW46bWYpDwKxwDgGzwjkEzArnEDArnEPArHCttgh7Elt7iUMO8ndRdQvxolwLEPJtwLP9fIvwbH9DcmzX1k+SY138JWT4fC5DzrUBky3ABbOJ741IV+xXAmaFcwiYFc4hYFY4h4BZ4RwCZoVzCJgVziFgVriWlxL32NK7IjFa89eKc/MICptDULccODcXIDcPAODTzPi5/vrk2Kb1k/k1uByXIWfnAqTmASwcNzEemVuO+5WAWeEcAmaFcwiYFc4hYFY4h4BZ4RwCZoVrtUU4z4Azg5VbgadrlhKfjnRb5fQg3boajqfaknAqMzbcdlN6bD6/7SfzVzbedq2WA+dagJBvA2bH5vJfg9n+VHJsbi7/bdifS28738//Hou5zHhuDFA//T2nuXybr3c+Pd6rWTWfawOmWoALIrmUeIwWoaSnJJ2QdGjRYw9KOirpYPXfN+v2Y2aTaZS3Az8Eblvh8cciYnf138urW5aZtaU2BCLiNeBkC7WYWQfGuTB4j6S3qrcL21JPkrRP0oykmd/+tv6mTGbWrqYh8DhwA7AbOAY8knpiROyPiOmImP7iF92MMJs0jX4qI+J4RMxHxAB4Arh5dcsys7Y0ahFK2hkRx6pP7wQO5Z6/YBCRbAXmWoCQbwPmWoCQbwPmWoCQb+XlWoB1207iSsC68VwbMNcChHwbMNcChHwbMNsChGwbMNcChHwbMNcChHwbsFfTXmRj+mtf91s7+YZ7Nn3M2hCQ9AxwK3CNpPeBB4BbJe1muBrzCHB33X7MbDLVhkBE7Fnh4SfXoBYz64Cv1JkVziFgVjiHgFnhHAJmhXMImBWu5aXESs4H8HLg5ePtLweG5nMBvBx42Xhm36q5MbM2pr++dXdITp2N7JyHmn2a2eecQ8CscA4Bs8I5BMwK5xAwK5xDwKxw7bcIE61ALwdeqovlwNC8DejlwMuP22y/AGxIf41qFiGnW4hn0+fQrwTMCucQMCucQ8CscA4Bs8I5BMwK5xAwK5xDwKxwrc4TGISS8wG8HHipLpYDQ/O5AF4OPPq+ezXbxsbm8wSS4/JSYjNLcAiYFc4hYFY4h4BZ4RwCZoVzCJgVruWlxL1kK9DLgUcfX6vlwNC8DejlwMv33WwMIDY0/7FM/h/1xmgRSrpO0s8lvSvpHUnfqx7fLukVSb+q/t3WqGoz69Qobwf6wPcj4ivAnwLflfQV4D7g1Yi4EXi1+tzMLjO1IRARxyLizerj08BhYBdwO3CgetoB4I61KtLM1s4lXRiUdD1wE/A6sCMijlVDHwA7VrUyM2vFyCEgaQvwHHBvRJxaPBYRQeL2ZpL2SZqRNHPqZN3N1cysbSOFgKT1DAPg6Yh4vnr4uKSd1fhO4MRK20bE/oiYjojpq7a32owwsxGM0h0Q8CRwOCIeXTT0ErC3+ngv8OLql2dma22UX81fA74NvC3pYPXY/cBDwLOSvgO8B9xVt6N5esn5AF4OvGy8g+XAMMZcAC8HHnm8N5f/28LjzBNIyiwlrj1aRPyC9ByErzcsycwmhKcNmxXOIWBWOIeAWeEcAmaFcwiYFa79uw0n2nleDrxUF8uBoXkb0MuBl4+n24BT5/Pbzm9Mf/3yDd4M323YzFIcAmaFcwiYFc4hYFY4h4BZ4RwCZoVzCJgVrt1bjkcvOR/Ay4GX6mQ5MDSeC+DlwEvl5gLUHXewofFsgOQ8gvA8ATNLcQiYFc4hYFY4h4BZ4RwCZoVzCJgVrvW/SpxqBXo58FJdLAeG5m1ALwcefd9TNe3FwYY1+N2c2aVfCZgVziFgVjiHgFnhHAJmhXMImBXOIWBWOIeAWeFq5wlIug74EbADCGB/RPxA0oPA3wEfVk+9PyJezu1rEErOB/By4KW6WA4MzecCeDnwsm0z+6477mB97mvU7Pd2binxKJOF+sD3I+JNSVuBNyS9Uo09FhEPN6rKzCbCKH+a/BhwrPr4tKTDwK61LszM2nFJry0kXQ/cBLxePXSPpLckPSVp2yrXZmYtGDkEJG0BngPujYhTwOPADcBuhq8UHklst0/SjKSZcx/PrkLJZraaRgoBSesZBsDTEfE8QEQcj4j5iBgATwA3r7RtROyPiOmImN60LX/xz8zaVxsCkgQ8CRyOiEcXPb5z0dPuBA6tfnlmttZG6Q58Dfg28Lakg9Vj9wN7JO1m2DY8Atxdt6Oegi1Tfkswrvma8VwDKsaYGjLIjuZbj7mqejXb5o87juY1j7/vtZL4+mbKGaU78IvELrJzAszs8uAZg2aFcwiYFc4hYFY4h4BZ4RwCZoVzCJgVrtVbjk8xYOvUZ20eski5eQR1ne+m8wjqe/m5vnm+qtw8grWbQwDj1Nx8v2skc0i/EjArnEPArHAOAbPCOQTMCucQMCucQ8CscO22CDXg6qlP2zykLeNlyKvl8lqGHL3MnaJX/WhmdllxCJgVziFgVjiHgFnhHAJmhXMImBXOIWBWuFbnCfQUXko84ZouQ167OQTgZcij7rfZZn4lYFY4h4BZ4RwCZoVzCJgVziFgVjiHgFnhFDFOu+ISDyZ9CLy36KFrgI9aK2A0rmk0rml0k1DX70fEl1YaaDUEfufg0kxETHdWwApc02hc0+gmta4FfjtgVjiHgFnhug6B/R0ffyWuaTSuaXSTWhfQ8TUBM+te168EzKxjDgGzwjkEzArnEDArnEPArHD/D5s+V/81WM0TAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "x_e: (4, 15), x_p: (5, 15), distance to goal: 17.80 distance to pursuer: 1.00:  16%|█▌        | 16/100 [00:00<00:00, 242.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "game over((\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "No, I did not escape"
      ],
      "metadata": {
        "id": "B8q9ETFGdmeO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2> Task 2: Monte Carlo Tree Search </h2>"
      ],
      "metadata": {
        "id": "-2H39Tw5iGc-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A. Why do you think we have proposed the restriction of expanding only non-visited states?"
      ],
      "metadata": {
        "id": "rTSp427wzY77"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The restriction of expanding only non-visited states have been proposed because we couldn't ensure that the policy tree would expand appropriately with a restricted amount of samples."
      ],
      "metadata": {
        "id": "5SEB-QmmFOY3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "B. Implement MCTS."
      ],
      "metadata": {
        "id": "sRuYXwcN2Zvo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class State:\n",
        "\tdef __init__(self,x_e,x_p,turn,goal,is_expanded=False,is_simulated=False, parent=None):\n",
        "\t\tself.evader = x_e\n",
        "\t\tself.pursuer = x_p\n",
        "\t\tself.turn = turn\n",
        "\t\tself.goal = goal\n",
        "\t\tself.is_expanded = is_expanded\n",
        "\t\tself.is_simulated = is_simulated\n",
        "\t\tself.visited = 0\n",
        "\t\tself.reward = 0\n",
        "\t\tself.parent = parent\n",
        "\t\tself.children = 0\n",
        "\t\tself.is_terminal = self.evader == self.goal\n",
        "\tdef __str__(self):\n",
        "\t\treturn f\"\"\"evader={self.evader}, pursuer={self.pursuer}, turn={self.turn},\n",
        "\t\t{self.is_expanded =},{self.is_simulated =}, {self.visited =}, reward={self.reward}\"\"\"\n",
        "\tdef get_action(self, root):\n",
        "\t\taction = tuple(np.array(self.evader)-np.array(root.evader))\n",
        "\t\tassert action in action_space, f'{action}'\n",
        "\t\treturn action\n",
        "\tdef get_location(self):\n",
        "\t\treturn [self.evader,self.pursuer,self.turn]\n",
        "\n",
        "def unexplored_node(env, node, Tree):\n",
        "\tif len(Tree[node]) == 0:\n",
        "\t\treturn True\n",
        "\tfor child in Tree[node]:\n",
        "\t\tif child.is_simulated == False:\n",
        "\t\t\treturn True\n",
        "\treturn False\n",
        "\n",
        "def get_children(env,state,discovered_nodes):\n",
        "\t\tassert state.children == 0\n",
        "\t\tif state.evader == state.goal:\n",
        "\t\t\treturn []\n",
        "\t\tchildren =[]\n",
        "\t\tfor action in action_space:\n",
        "\t\t\tif state.turn == 'evader':\n",
        "\t\t\t\tnode = state.evader\n",
        "\t\t\telif state.turn == 'pursuer':\n",
        "\t\t\t\tnode = state.pursuer\n",
        "\t\t\tmay_child, is_child = transition_function(env, node, action)\n",
        "\t\t\tif is_child:\n",
        "\t\t\t\tif state.turn == 'evader':\n",
        "\t\t\t\t\tchild_state = State(may_child,state.pursuer,'pursuer',state.goal,parent=state)\n",
        "\t\t\t\telif state.turn == 'pursuer':\n",
        "\t\t\t\t\tchild_state = State(state.evader,may_child,'evader',state.goal,parent=state)\n",
        "\t\t\t\tif child_state.get_location() not in discovered_nodes:\n",
        "\t\t\t\t\tchildren.append(child_state)\n",
        "\t\tstate.children = len(children)\n",
        "\t\treturn children\n",
        "\n",
        "def expand(env, node, Tree, discovered_nodes):\n",
        "\tif not node.is_expanded:\n",
        "\t\tchildren = get_children(env, node, discovered_nodes)\n",
        "\t\tTree[node] = children\n",
        "\t\tdiscovered_nodes.extend([child.get_location() for child in children])\n",
        "\t\tnode.is_expanded = True\n",
        "\n",
        "def child_select(node, Tree, weight=2**0.5):\n",
        "\t\tchildren = Tree[node]\n",
        "\t\tassert all(child.is_simulated for child in children)\n",
        "\t\tvertex = math.log(node.visited)\n",
        "\t\tdef bound(child):\n",
        "\t\t\t\treturn child.reward / child.visited + weight * (vertex / child.visited)**0.5\n",
        "\t\treturn max(children, key=bound)\n",
        "\n",
        "def simulation(x_e=x_e, x_p=x_p, turn:str='evader', policy=default_policy):\n",
        "    accumulated_reward = 0\n",
        "    for s in range(100):\n",
        "        distance_to_goal = np.linalg.norm(np.array(x_e) - np.array(goal))\n",
        "        if distance_to_goal != 0:\n",
        "            accumulated_reward += 0.1/distance_to_goal\n",
        "        else:\n",
        "            accumulated_reward += 100\n",
        "        # according to the optimal policy of the evader, move the evader\n",
        "        u_e = action_space[policy[x_e]]  # default_policy without taking into account the pursuer\n",
        "        if not (s == 0 and turn=='pursuer'):\n",
        "            x_e, _ = transition_function(environment, x_e, u_e)\n",
        "        \n",
        "        if x_e == goal:\n",
        "            return 100 + accumulated_reward - (s+1)\n",
        "\n",
        "        # propagate the pursuer: TODO uncomment the next line to release the beast\n",
        "        x_p = pursuer_transition(environment,x_e, x_p)\n",
        "        if x_p == x_e:\n",
        "            return 0\n",
        "    return accumulated_reward\n",
        "\n",
        "def re_simulation(node, policy):\n",
        "\treturn simulation(node.evader, node.pursuer, node.turn, policy)\n",
        "\n",
        "def is_root(node):\n",
        "\treturn node.parent is None\n",
        "\n",
        "def backpropagate(node, reward):\n",
        "\tnode.visited += 1\n",
        "\tnode.reward += reward\n",
        "\tif node.parent is None: return\n",
        "\tbackpropagate(node.parent, reward)\n",
        "\n",
        "def best_child(node, Tree):\n",
        "\tchildren = Tree[node]\n",
        "\tdef visits(child):\n",
        "\t\treturn child.visited\n",
        "\treturn max(children.visited)\n",
        "\n",
        "def plot_explored(env, Tree, node):\n",
        "\tcurrent_env = np.copy(env)\n",
        "\tfor node_ in Tree.keys():\n",
        "\t\tchildren = Tree[node_]\n",
        "\t\tevaders = [child.evader for child in children]+[node_.evader]\n",
        "\t\tpursuers = [child.pursuer for child in children]+[node_.pursuer]\n",
        "\t\tgoal = node_.goal\n",
        "\t\tfor evader in evaders:\n",
        "\t\t\tcurrent_env[evader] = 0.9  # yellow\n",
        "\t\tcurrent_env[node.evader] = 1\n",
        "\t\t# plot pursuer\n",
        "\t\tfor pursuer in pursuers:\n",
        "\t\t\tcurrent_env[pursuer] = 0.6  # cyan-ish\n",
        "\t\tcurrent_env[node.pursuer] = 0.4  # cyan-ish\n",
        "\t\t# plot goal\n",
        "\t\tcurrent_env[goal] = 0.3\n",
        "\tplt.close()\n",
        "\tfig = plt.figure()\n",
        "\tax = fig.gca()\n",
        "\tax.pcolormesh(current_env, edgecolors='k', linewidth=1)\n",
        "\tax.set_aspect('equal')\n",
        "\tax.invert_yaxis()\n",
        "\tplt.show()"
      ],
      "metadata": {
        "id": "5DWg6Fa22dEa"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mcts(env: np.array, x_e: Tuple, x_p: Tuple, goal: Tuple, k: int, default_policy) -> Tuple:\n",
        "\t\"\"\"\n",
        "\tMonte-Carlo tree search\n",
        "\tenv is the grid enviroment\n",
        "\tx_e evader\n",
        "\tx_p pursuer\n",
        "\tgoal is the goal state\n",
        "\tu is an optimal action\n",
        "\t\"\"\"\n",
        "\tTree = defaultdict(list)\n",
        "\troot = State(x_e, x_p,'evader', goal, False)\n",
        "\tdiscovered_nodes = [root.get_location()]\n",
        "\texpand(env, root, Tree, discovered_nodes)\n",
        "\tfor child in Tree[root]:\n",
        "\t\tif child.is_terminal:\n",
        "\t\t\treturn child.get_action(root)\n",
        "\tpbar = tqdm(total=k, desc='inner_loop', leave=False)\n",
        "\twhile k > 0:\n",
        "\t\tnode = root\n",
        "\t\twhile not unexplored_node(env, node, Tree):\n",
        "\t\t\tnode = child_select(node,Tree)\n",
        "\t\tif node.visited != 0 or is_root(node) : # or not node.is_simulated i guess\n",
        "\t\t\texpand(env, node, Tree, discovered_nodes)\n",
        "\t\t\tnot_explored_children = [child for child in Tree[node] if child.visited == 0]\n",
        "\t\t\tif len(not_explored_children) != 0:\n",
        "\t\t\t\tnode = np.random.choice(not_explored_children)\n",
        "\t\treward = re_simulation(node, default_policy)\n",
        "\t\tnode.is_simulated = True\n",
        "\t\tbackpropagate(node, reward)\n",
        "\t\tk-=1\n",
        "\t\tpbar.update(1)\n",
        "\tu = best_child(root,Tree).get_action(root)\n",
        "\treturn u"
      ],
      "metadata": {
        "id": "u4IkFTk7Nx9M"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (row index, colum index). In the image row corresponds to y, and colum to x.\n",
        "x_e = tuple(data[\"x_e\"])  # (11, 6) you free to use it as np array if you prefer, but utils.py is expecting a tuple\n",
        "x_p = tuple(data[\"x_p\"])  # (7, 25)\n",
        "goal = tuple(data[\"goal\"])  # (15, 29)\n",
        "\n",
        "# task 1 VI for evader\n",
        "# ======================================\n",
        "default_policy, Gopt = vi(environment, goal)\n",
        "\n",
        "# visualize the optimal policy\n",
        "#plt.matshow(Gopt)\n",
        "\n",
        "# task2 MCTS\n",
        "# ======================================\n",
        "u = mcts(environment, x_e, x_p, goal, 100, default_policy)  # here is just to check\n",
        "\n",
        "# Visualization\n",
        "# ======================================\n",
        "im = plot_joint_enviroment(environment, x_e, x_p, goal)\n",
        "plt.matshow(im)\n",
        "plt.show()\n",
        "\n",
        "# The Game\n",
        "fig = plt.figure()\n",
        "imgs = []\n",
        "pbar = tqdm(range(100))\n",
        "for s in pbar:\n",
        "    im = plot_joint_enviroment(environment, x_e, x_p, goal)\n",
        "    plot = plt.imshow(im)\n",
        "    imgs.append([plot])\n",
        "    # according to the optimal policy of the evader, move the evader\n",
        "    #u_e = action_space[default_policy[x_e]]  # default_policy without taking into account the pursuer\n",
        "    u_e = mcts(environment, x_e, x_p, goal, 100, default_policy)  # taking into account pursuer, simulating the game\n",
        "    x_e, _ = transition_function(environment, x_e, u_e)\n",
        "    if x_e == goal:\n",
        "        print('WIN!')\n",
        "        break\n",
        "    # propagate the pursuer: TODO uncomment the next line to release the beast\n",
        "    x_p = pursuer_transition(environment,x_e, x_p)\n",
        "    if x_p == x_e:\n",
        "        print('game over((')\n",
        "        break\n",
        "    pbar.set_description(f'x_e: {x_e}, x_p: {x_p},'\n",
        "                         f' distance to goal: {np.linalg.norm(np.array(x_e) - np.array(goal)):0.2f}'\n",
        "                         f' distance to pursuer: {np.linalg.norm(np.array(x_e) - np.array(x_p)):0.2f}')\n",
        "im = plot_joint_enviroment(environment, x_e, x_p, goal)\n",
        "plot = plt.imshow(im)\n",
        "imgs.append([plot])\n",
        "ani = animation.ArtistAnimation(fig, imgs, interval=100, blit=True)\n",
        "ani.save('/escape_mcts.mp4')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FomCtJEr51Xi",
        "outputId": "a46d5d08-6cf7-41c8-8206-ae485a3a6b95"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "inner_loop:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
            "                                                   \u001b[A"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "inner_loop:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "inner_loop:  84%|████████▍ | 84/100 [00:00<00:00, 834.53it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                             \u001b[A\u001b[A\n",
            "x_e: (12, 6), x_p: (7, 24), distance to goal: 23.19 distance to pursuer: 18.68:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
            "x_e: (12, 6), x_p: (7, 24), distance to goal: 23.19 distance to pursuer: 18.68:   1%|          | 1/100 [00:00<00:17,  5.66it/s]\u001b[A\n",
            "\n",
            "inner_loop:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                   \u001b[A\u001b[A\n",
            "x_e: (11, 6), x_p: (7, 23), distance to goal: 23.35 distance to pursuer: 17.46:   1%|          | 1/100 [00:00<00:17,  5.66it/s]\u001b[A\n",
            "x_e: (11, 6), x_p: (7, 23), distance to goal: 23.35 distance to pursuer: 17.46:   2%|▏         | 2/100 [00:00<00:14,  6.81it/s]\u001b[A\n",
            "\n",
            "inner_loop:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "inner_loop:  77%|███████▋  | 77/100 [00:00<00:00, 762.71it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                             \u001b[A\u001b[A\n",
            "x_e: (12, 6), x_p: (7, 22), distance to goal: 23.19 distance to pursuer: 16.76:   2%|▏         | 2/100 [00:00<00:14,  6.81it/s]\u001b[A\n",
            "x_e: (12, 6), x_p: (7, 22), distance to goal: 23.19 distance to pursuer: 16.76:   3%|▎         | 3/100 [00:00<00:15,  6.45it/s]\u001b[A\n",
            "\n",
            "inner_loop:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "inner_loop:  75%|███████▌  | 75/100 [00:00<00:00, 746.92it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                             \u001b[A\u001b[A\n",
            "x_e: (13, 6), x_p: (7, 21), distance to goal: 23.09 distance to pursuer: 16.16:   3%|▎         | 3/100 [00:00<00:15,  6.45it/s]\u001b[A\n",
            "x_e: (13, 6), x_p: (7, 21), distance to goal: 23.09 distance to pursuer: 16.16:   4%|▍         | 4/100 [00:00<00:15,  6.28it/s]\u001b[A\n",
            "\n",
            "inner_loop:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "inner_loop:  67%|██████▋   | 67/100 [00:00<00:00, 665.96it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                             \u001b[A\u001b[A\n",
            "x_e: (14, 6), x_p: (8, 21), distance to goal: 23.02 distance to pursuer: 16.16:   4%|▍         | 4/100 [00:00<00:15,  6.28it/s]\u001b[A\n",
            "x_e: (14, 6), x_p: (8, 21), distance to goal: 23.02 distance to pursuer: 16.16:   5%|▌         | 5/100 [00:00<00:16,  5.94it/s]\u001b[A\n",
            "\n",
            "inner_loop:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "inner_loop:  72%|███████▏  | 72/100 [00:00<00:00, 715.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                             \u001b[A\u001b[A\n",
            "x_e: (15, 6), x_p: (8, 20), distance to goal: 23.00 distance to pursuer: 15.65:   5%|▌         | 5/100 [00:00<00:16,  5.94it/s]\u001b[A\n",
            "x_e: (15, 6), x_p: (8, 20), distance to goal: 23.00 distance to pursuer: 15.65:   6%|▌         | 6/100 [00:00<00:15,  5.91it/s]\u001b[A\n",
            "\n",
            "inner_loop:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "inner_loop:  64%|██████▍   | 64/100 [00:00<00:00, 635.76it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                             \u001b[A\u001b[A\n",
            "x_e: (16, 6), x_p: (8, 19), distance to goal: 23.02 distance to pursuer: 15.26:   6%|▌         | 6/100 [00:01<00:15,  5.91it/s]\u001b[A\n",
            "x_e: (16, 6), x_p: (8, 19), distance to goal: 23.02 distance to pursuer: 15.26:   7%|▋         | 7/100 [00:01<00:16,  5.76it/s]\u001b[A\n",
            "\n",
            "inner_loop:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "inner_loop:  72%|███████▏  | 72/100 [00:00<00:00, 714.64it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                             \u001b[A\u001b[A\n",
            "x_e: (17, 6), x_p: (9, 19), distance to goal: 23.09 distance to pursuer: 15.26:   7%|▋         | 7/100 [00:01<00:16,  5.76it/s]\u001b[A\n",
            "x_e: (17, 6), x_p: (9, 19), distance to goal: 23.09 distance to pursuer: 15.26:   8%|▊         | 8/100 [00:01<00:16,  5.74it/s]\u001b[A\n",
            "\n",
            "inner_loop:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "inner_loop:  66%|██████▌   | 66/100 [00:00<00:00, 658.36it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                             \u001b[A\u001b[A\n",
            "x_e: (18, 6), x_p: (9, 18), distance to goal: 23.19 distance to pursuer: 15.00:   8%|▊         | 8/100 [00:01<00:16,  5.74it/s]\u001b[A\n",
            "x_e: (18, 6), x_p: (9, 18), distance to goal: 23.19 distance to pursuer: 15.00:   9%|▉         | 9/100 [00:01<00:15,  5.79it/s]\u001b[A\n",
            "\n",
            "inner_loop:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "inner_loop:  83%|████████▎ | 83/100 [00:00<00:00, 824.40it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                             \u001b[A\u001b[A\n",
            "x_e: (19, 6), x_p: (9, 17), distance to goal: 23.35 distance to pursuer: 14.87:   9%|▉         | 9/100 [00:01<00:15,  5.79it/s]\u001b[A\n",
            "x_e: (19, 6), x_p: (9, 17), distance to goal: 23.35 distance to pursuer: 14.87:  10%|█         | 10/100 [00:01<00:14,  6.06it/s]\u001b[A\n",
            "\n",
            "inner_loop:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "inner_loop:  57%|█████▋    | 57/100 [00:00<00:00, 566.62it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                             \u001b[A\u001b[A\n",
            "x_e: (19, 7), x_p: (10, 17), distance to goal: 22.36 distance to pursuer: 13.45:  10%|█         | 10/100 [00:01<00:14,  6.06it/s]\u001b[A\n",
            "x_e: (19, 7), x_p: (10, 17), distance to goal: 22.36 distance to pursuer: 13.45:  11%|█         | 11/100 [00:01<00:15,  5.74it/s]\u001b[A\n",
            "\n",
            "inner_loop:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "inner_loop:  93%|█████████▎| 93/100 [00:00<00:00, 924.77it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                             \u001b[A\u001b[A\n",
            "x_e: (19, 8), x_p: (10, 16), distance to goal: 21.38 distance to pursuer: 12.04:  11%|█         | 11/100 [00:02<00:15,  5.74it/s]\u001b[A\n",
            "x_e: (19, 8), x_p: (10, 16), distance to goal: 21.38 distance to pursuer: 12.04:  12%|█▏        | 12/100 [00:02<00:14,  5.99it/s]\u001b[A\n",
            "\n",
            "inner_loop:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "inner_loop:  77%|███████▋  | 77/100 [00:00<00:00, 764.39it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                             \u001b[A\u001b[A\n",
            "x_e: (20, 8), x_p: (11, 15), distance to goal: 21.59 distance to pursuer: 11.40:  12%|█▏        | 12/100 [00:02<00:14,  5.99it/s]\u001b[A\n",
            "x_e: (20, 8), x_p: (11, 15), distance to goal: 21.59 distance to pursuer: 11.40:  13%|█▎        | 13/100 [00:02<00:14,  5.88it/s]\u001b[A\n",
            "\n",
            "inner_loop:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "inner_loop:  83%|████████▎ | 83/100 [00:00<00:00, 824.15it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                             \u001b[A\u001b[A\n",
            "x_e: (21, 8), x_p: (11, 15), distance to goal: 21.84 distance to pursuer: 12.21:  13%|█▎        | 13/100 [00:02<00:14,  5.88it/s]\u001b[A\n",
            "x_e: (21, 8), x_p: (11, 15), distance to goal: 21.84 distance to pursuer: 12.21:  14%|█▍        | 14/100 [00:02<00:14,  5.86it/s]\u001b[A\n",
            "\n",
            "inner_loop:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "inner_loop:  62%|██████▏   | 62/100 [00:00<00:00, 616.67it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                             \u001b[A\u001b[A\n",
            "x_e: (22, 8), x_p: (11, 15), distance to goal: 22.14 distance to pursuer: 13.04:  14%|█▍        | 14/100 [00:02<00:14,  5.86it/s]\u001b[A\n",
            "x_e: (22, 8), x_p: (11, 15), distance to goal: 22.14 distance to pursuer: 13.04:  15%|█▌        | 15/100 [00:02<00:14,  5.76it/s]\u001b[A\n",
            "\n",
            "inner_loop:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "inner_loop:  99%|█████████▉| 99/100 [00:00<00:00, 984.40it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                             \u001b[A\u001b[A\n",
            "x_e: (23, 8), x_p: (11, 15), distance to goal: 22.47 distance to pursuer: 13.89:  15%|█▌        | 15/100 [00:02<00:14,  5.76it/s]\u001b[A\n",
            "x_e: (23, 8), x_p: (11, 15), distance to goal: 22.47 distance to pursuer: 13.89:  16%|█▌        | 16/100 [00:02<00:14,  5.97it/s]\u001b[A\n",
            "\n",
            "inner_loop:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "inner_loop:  69%|██████▉   | 69/100 [00:00<00:00, 687.10it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                             \u001b[A\u001b[A\n",
            "x_e: (24, 8), x_p: (11, 15), distance to goal: 22.85 distance to pursuer: 14.76:  16%|█▌        | 16/100 [00:02<00:14,  5.97it/s]\u001b[A\n",
            "x_e: (24, 8), x_p: (11, 15), distance to goal: 22.85 distance to pursuer: 14.76:  17%|█▋        | 17/100 [00:02<00:13,  5.94it/s]\u001b[A\n",
            "\n",
            "inner_loop:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "inner_loop:  96%|█████████▌| 96/100 [00:00<00:00, 956.40it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                             \u001b[A\u001b[A\n",
            "x_e: (24, 9), x_p: (11, 15), distance to goal: 21.93 distance to pursuer: 14.32:  17%|█▋        | 17/100 [00:03<00:13,  5.94it/s]\u001b[A\n",
            "x_e: (24, 9), x_p: (11, 15), distance to goal: 21.93 distance to pursuer: 14.32:  18%|█▊        | 18/100 [00:03<00:13,  6.02it/s]\u001b[A\n",
            "\n",
            "inner_loop:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "inner_loop:  89%|████████▉ | 89/100 [00:00<00:00, 889.83it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                             \u001b[A\u001b[A\n",
            "x_e: (24, 10), x_p: (11, 15), distance to goal: 21.02 distance to pursuer: 13.93:  18%|█▊        | 18/100 [00:03<00:13,  6.02it/s]\u001b[A\n",
            "x_e: (24, 10), x_p: (11, 15), distance to goal: 21.02 distance to pursuer: 13.93:  19%|█▉        | 19/100 [00:03<00:13,  6.08it/s]\u001b[A\n",
            "\n",
            "inner_loop:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "inner_loop:  57%|█████▋    | 57/100 [00:00<00:00, 557.52it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                             \u001b[A\u001b[A\n",
            "x_e: (24, 11), x_p: (11, 15), distance to goal: 20.12 distance to pursuer: 13.60:  19%|█▉        | 19/100 [00:03<00:13,  6.08it/s]\u001b[A\n",
            "x_e: (24, 11), x_p: (11, 15), distance to goal: 20.12 distance to pursuer: 13.60:  20%|██        | 20/100 [00:03<00:14,  5.59it/s]\u001b[A\n",
            "\n",
            "inner_loop:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "inner_loop:  59%|█████▉    | 59/100 [00:00<00:00, 587.16it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                             \u001b[A\u001b[A\n",
            "x_e: (24, 12), x_p: (11, 15), distance to goal: 19.24 distance to pursuer: 13.34:  20%|██        | 20/100 [00:03<00:14,  5.59it/s]\u001b[A\n",
            "x_e: (24, 12), x_p: (11, 15), distance to goal: 19.24 distance to pursuer: 13.34:  21%|██        | 21/100 [00:03<00:14,  5.31it/s]\u001b[A\n",
            "\n",
            "inner_loop:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                   \u001b[A\u001b[A\n",
            "x_e: (24, 13), x_p: (11, 15), distance to goal: 18.36 distance to pursuer: 13.15:  21%|██        | 21/100 [00:03<00:14,  5.31it/s]\u001b[A\n",
            "x_e: (24, 13), x_p: (11, 15), distance to goal: 18.36 distance to pursuer: 13.15:  22%|██▏       | 22/100 [00:03<00:13,  5.84it/s]\u001b[A\n",
            "\n",
            "inner_loop:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                   \u001b[A\u001b[A\n",
            "x_e: (24, 14), x_p: (11, 15), distance to goal: 17.49 distance to pursuer: 13.04:  22%|██▏       | 22/100 [00:03<00:13,  5.84it/s]\u001b[A\n",
            "x_e: (24, 14), x_p: (11, 15), distance to goal: 17.49 distance to pursuer: 13.04:  23%|██▎       | 23/100 [00:03<00:12,  6.33it/s]\u001b[A\n",
            "\n",
            "inner_loop:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                   \u001b[A\u001b[A\n",
            "x_e: (24, 15), x_p: (11, 15), distance to goal: 16.64 distance to pursuer: 13.00:  23%|██▎       | 23/100 [00:03<00:12,  6.33it/s]\u001b[A\n",
            "x_e: (24, 15), x_p: (11, 15), distance to goal: 16.64 distance to pursuer: 13.00:  24%|██▍       | 24/100 [00:03<00:11,  6.86it/s]\u001b[A\n",
            "\n",
            "inner_loop:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                   \u001b[A\u001b[A\n",
            "x_e: (24, 16), x_p: (11, 15), distance to goal: 15.81 distance to pursuer: 13.04:  24%|██▍       | 24/100 [00:04<00:11,  6.86it/s]\u001b[A\n",
            "x_e: (24, 16), x_p: (11, 15), distance to goal: 15.81 distance to pursuer: 13.04:  25%|██▌       | 25/100 [00:04<00:10,  7.23it/s]\u001b[A\n",
            "\n",
            "inner_loop:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                   \u001b[A\u001b[A\n",
            "x_e: (24, 17), x_p: (11, 15), distance to goal: 15.00 distance to pursuer: 13.15:  25%|██▌       | 25/100 [00:04<00:10,  7.23it/s]\u001b[A\n",
            "x_e: (24, 17), x_p: (11, 15), distance to goal: 15.00 distance to pursuer: 13.15:  26%|██▌       | 26/100 [00:04<00:09,  7.74it/s]\u001b[A\n",
            "\n",
            "inner_loop:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                   \u001b[A\u001b[A\n",
            "x_e: (24, 18), x_p: (11, 15), distance to goal: 14.21 distance to pursuer: 13.34:  26%|██▌       | 26/100 [00:04<00:09,  7.74it/s]\u001b[A\n",
            "x_e: (24, 18), x_p: (11, 15), distance to goal: 14.21 distance to pursuer: 13.34:  27%|██▋       | 27/100 [00:04<00:09,  7.98it/s]\u001b[A\n",
            "\n",
            "inner_loop:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                   \u001b[A\u001b[A\n",
            "x_e: (24, 19), x_p: (11, 15), distance to goal: 13.45 distance to pursuer: 13.60:  27%|██▋       | 27/100 [00:04<00:09,  7.98it/s]\u001b[A\n",
            "x_e: (24, 19), x_p: (11, 15), distance to goal: 13.45 distance to pursuer: 13.60:  28%|██▊       | 28/100 [00:04<00:08,  8.44it/s]\u001b[A\n",
            "\n",
            "inner_loop:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "inner_loop:  98%|█████████▊| 98/100 [00:00<00:00, 964.49it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                             \u001b[A\u001b[A\n",
            "x_e: (24, 20), x_p: (11, 15), distance to goal: 12.73 distance to pursuer: 13.93:  28%|██▊       | 28/100 [00:04<00:08,  8.44it/s]\u001b[A\n",
            "x_e: (24, 20), x_p: (11, 15), distance to goal: 12.73 distance to pursuer: 13.93:  29%|██▉       | 29/100 [00:04<00:08,  7.89it/s]\u001b[A\n",
            "\n",
            "inner_loop:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                   \u001b[A\u001b[A\n",
            "x_e: (24, 21), x_p: (11, 15), distance to goal: 12.04 distance to pursuer: 14.32:  29%|██▉       | 29/100 [00:04<00:08,  7.89it/s]\u001b[A\n",
            "x_e: (24, 21), x_p: (11, 15), distance to goal: 12.04 distance to pursuer: 14.32:  30%|███       | 30/100 [00:04<00:08,  8.26it/s]\u001b[A\n",
            "\n",
            "inner_loop:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                   \u001b[A\u001b[A\n",
            "x_e: (24, 22), x_p: (11, 15), distance to goal: 11.40 distance to pursuer: 14.76:  30%|███       | 30/100 [00:04<00:08,  8.26it/s]\u001b[A\n",
            "\n",
            "inner_loop:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                   \u001b[A\u001b[A\n",
            "x_e: (24, 23), x_p: (11, 16), distance to goal: 10.82 distance to pursuer: 14.76:  30%|███       | 30/100 [00:04<00:08,  8.26it/s]\u001b[A\n",
            "x_e: (24, 23), x_p: (11, 16), distance to goal: 10.82 distance to pursuer: 14.76:  32%|███▏      | 32/100 [00:04<00:07,  9.33it/s]\u001b[A\n",
            "\n",
            "inner_loop:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                   \u001b[A\u001b[A\n",
            "x_e: (24, 24), x_p: (12, 16), distance to goal: 10.30 distance to pursuer: 14.42:  32%|███▏      | 32/100 [00:04<00:07,  9.33it/s]\u001b[A\n",
            "\n",
            "inner_loop:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                   \u001b[A\u001b[A\n",
            "x_e: (24, 25), x_p: (12, 16), distance to goal: 9.85 distance to pursuer: 15.00:  32%|███▏      | 32/100 [00:05<00:07,  9.33it/s] \u001b[A\n",
            "x_e: (24, 25), x_p: (12, 16), distance to goal: 9.85 distance to pursuer: 15.00:  34%|███▍      | 34/100 [00:05<00:06, 10.28it/s]\u001b[A\n",
            "\n",
            "inner_loop:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "x_e: (24, 26), x_p: (12, 16), distance to goal: 9.49 distance to pursuer: 15.62:  34%|███▍      | 34/100 [00:05<00:06, 10.28it/s]\u001b[A\n",
            "\n",
            "                                                   \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "inner_loop:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "                                                   \u001b[A\u001b[A\u001b[A\n",
            "x_e: (25, 26), x_p: (12, 17), distance to goal: 10.44 distance to pursuer: 15.81:  34%|███▍      | 34/100 [00:05<00:06, 10.28it/s]\u001b[A\n",
            "x_e: (25, 26), x_p: (12, 17), distance to goal: 10.44 distance to pursuer: 15.81:  36%|███▌      | 36/100 [00:05<00:05, 10.70it/s]\u001b[A\n",
            "\n",
            "inner_loop:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                   \u001b[A\u001b[A\n",
            "x_e: (25, 27), x_p: (13, 17), distance to goal: 10.20 distance to pursuer: 15.62:  36%|███▌      | 36/100 [00:05<00:05, 10.70it/s]\u001b[A\n",
            "\n",
            "inner_loop:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                   \u001b[A\u001b[A\n",
            "x_e: (25, 28), x_p: (13, 17), distance to goal: 10.05 distance to pursuer: 16.28:  36%|███▌      | 36/100 [00:05<00:05, 10.70it/s]\u001b[A\n",
            "x_e: (25, 28), x_p: (13, 17), distance to goal: 10.05 distance to pursuer: 16.28:  38%|███▊      | 38/100 [00:05<00:05, 11.07it/s]\u001b[A\n",
            "\n",
            "inner_loop:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                   \u001b[A\u001b[A\n",
            "x_e: (24, 28), x_p: (13, 17), distance to goal: 9.06 distance to pursuer: 15.56:  38%|███▊      | 38/100 [00:05<00:05, 11.07it/s] \u001b[A\n",
            "\n",
            "inner_loop:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                   \u001b[A\u001b[A\n",
            "x_e: (23, 28), x_p: (13, 18), distance to goal: 8.06 distance to pursuer: 14.14:  38%|███▊      | 38/100 [00:05<00:05, 11.07it/s]\u001b[A\n",
            "x_e: (23, 28), x_p: (13, 18), distance to goal: 8.06 distance to pursuer: 14.14:  40%|████      | 40/100 [00:05<00:05, 11.43it/s]\u001b[A\n",
            "\n",
            "inner_loop:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                   \u001b[A\u001b[A\n",
            "x_e: (22, 28), x_p: (14, 18), distance to goal: 7.07 distance to pursuer: 12.81:  40%|████      | 40/100 [00:05<00:05, 11.43it/s]\u001b[A\n",
            "\n",
            "inner_loop:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                   \u001b[A\u001b[A\n",
            "x_e: (21, 28), x_p: (14, 18), distance to goal: 6.08 distance to pursuer: 12.21:  40%|████      | 40/100 [00:05<00:05, 11.43it/s]\u001b[A\n",
            "x_e: (21, 28), x_p: (14, 18), distance to goal: 6.08 distance to pursuer: 12.21:  42%|████▏     | 42/100 [00:05<00:04, 12.32it/s]\u001b[A\n",
            "\n",
            "inner_loop:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                   \u001b[A\u001b[A\n",
            "x_e: (20, 28), x_p: (14, 19), distance to goal: 5.10 distance to pursuer: 10.82:  42%|████▏     | 42/100 [00:05<00:04, 12.32it/s]\u001b[A\n",
            "\n",
            "inner_loop:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                   \u001b[A\u001b[A\n",
            "x_e: (19, 28), x_p: (14, 20), distance to goal: 4.12 distance to pursuer: 9.43:  42%|████▏     | 42/100 [00:05<00:04, 12.32it/s] \u001b[A\n",
            "x_e: (19, 28), x_p: (14, 20), distance to goal: 4.12 distance to pursuer: 9.43:  44%|████▍     | 44/100 [00:05<00:04, 13.44it/s]\u001b[A\n",
            "\n",
            "inner_loop:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                   \u001b[A\u001b[A\n",
            "x_e: (18, 28), x_p: (14, 21), distance to goal: 3.16 distance to pursuer: 8.06:  44%|████▍     | 44/100 [00:05<00:04, 13.44it/s]\u001b[A\n",
            "\n",
            "inner_loop:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                   \u001b[A\u001b[A\n",
            "x_e: (17, 28), x_p: (15, 21), distance to goal: 2.24 distance to pursuer: 7.28:  44%|████▍     | 44/100 [00:05<00:04, 13.44it/s]\u001b[A\n",
            "x_e: (17, 28), x_p: (15, 21), distance to goal: 2.24 distance to pursuer: 7.28:  46%|████▌     | 46/100 [00:05<00:03, 14.81it/s]\u001b[A\n",
            "\n",
            "inner_loop:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                   \u001b[A\u001b[A\n",
            "x_e: (16, 28), x_p: (15, 22), distance to goal: 1.41 distance to pursuer: 6.08:  46%|████▌     | 46/100 [00:05<00:03, 14.81it/s]\u001b[A\n",
            "\n",
            "inner_loop:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                   \u001b[A\u001b[A\n",
            "x_e: (15, 28), x_p: (15, 23), distance to goal: 1.00 distance to pursuer: 5.00:  48%|████▊     | 48/100 [00:05<00:06,  8.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WIN!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAALhElEQVR4nO3db6hc9Z3H8fe37jXin9KkbkOahtqKT0RoLJe0pbJYROtKIfpEmoJkQXp9UEGhD1bcB/WhLNXSR0JcQ7PF2hZUDKzU2iBIoRWjZGP+7KqVSJNek5Zs0RbWP/HbB/ekTNN7ZyYzZ+bMzff9guGe+Z2Zez4c8sk5Z35zZyIzkXTu+0jXASRNh2WXirDsUhGWXSrCsktFWHapiH8Y58kRcSPwfeA84D8y8/5+jz8/1uQFXDTOJiX18f/8mffy3VhuXYw6zx4R5wGvAtcDR4EXgW2ZeWil53w01uUX4rqRtidpsBdyD2/nyWXLPs5p/Bbg9cx8IzPfA34MbB3j90maoHHKvhH4bc/9o82YpBk01jX7MCJiAVgAuIALJ705SSsY58h+DNjUc/9TzdjfyMwdmTmfmfNzrBljc5LGMU7ZXwSuiIjPRMT5wNeB3e3EktS2kU/jM/ODiLgTeIalqbedmXmwtWSSWjXWNXtmPg083VIWSRPkO+ikIiy7VIRll4qw7FIRll0qwrJLRVh2qQjLLhVh2aUiLLtUhGWXirDsUhGWXSpi4p9Uo7PzzO/2dR1BZ+mrn9zcdYSheGSXirDsUhGWXSrCsktFWHapCMsuFeHU24xZLdM4Wn08sktFWHapCMsuFWHZpSIsu1SEZZeKGGvqLSKOAO8Ap4APMnO+jVBSBf3+wnESU7BtzLN/JTP/0MLvkTRBnsZLRYxb9gR+HhEvRcRCG4EkTca4p/HXZOaxiPgE8GxE/E9mPt/7gOY/gQWAC7hwzM1JGtVYR/bMPNb8PAE8CWxZ5jE7MnM+M+fnWDPO5iSNYeSyR8RFEXHJ6WXgBuBAW8EktWuc0/j1wJMRcfr3/Cgzf9ZKKkmtG7nsmfkG8LkWs0iaIKfepCIsu1SEZZeKsOxSEZZdKsKyS0VYdqkIyy4VYdmlIiy7VIRll4qw7FIRll0qwi92XEWm/WmkOrd4ZJeKsOxSEZZdKsKyS0VYdqkIyy4V4dTbKtJves1pOQ3ikV0qwrJLRVh2qQjLLhVh2aUiLLtUhGWXihg4zx4RO4GvAScy86pmbB3wE+Ay4Ahwa2b+3+Rizp5Zm9cedQ5+0HN17hjmyP4D4MYzxu4B9mTmFcCe5r6kGTaw7Jn5PHDyjOGtwK5meRdwc8u5JLVs1LfLrs/MxWb5LWD9Sg+MiAVgAeACLhxxc5LGNfYLdJmZQPZZvyMz5zNzfo41425O0ohGLfvxiNgA0Pw80V4kSZMwatl3A9ub5e3AU+3EkTQpw0y9PQZcC1waEUeB7wD3Az+NiNuBN4FbJxlS4xk0tTZr04iajIFlz8xtK6y6ruUskibId9BJRVh2qQjLLhVh2aUiLLtUhJ8uKz+1tgiP7FIRll0qwrJLRVh2qQjLLhVh2aUinHpTX36Q5bnDI7tUhGWXirDsUhGWXSrCsktFWHapCMsuFeE8u0bmp9auLh7ZpSIsu1SEZZeKsOxSEZZdKsKyS0UM88WOO4GvAScy86pm7D7gm8Dvm4fdm5lPTyqkVqfV9Km1b/xo5W1+9hv9/5S3C3+87UvLjp/6r1+v+Jxhjuw/AG5cZvx7mbm5uVl0acYNLHtmPg+cnEIWSRM0zjX7nRGxPyJ2RsTa1hJJmohRy/4QcDmwGVgEHljpgRGxEBF7I2Lv+7w74uYkjWuksmfm8cw8lZkfAg8DW/o8dkdmzmfm/BxrRs0paUwjlT0iNvTcvQU40E4cSZMyzNTbY8C1wKURcRT4DnBtRGwGEjgC3DHBjDoHzdq03CxOr/XzsR/+atnx8/LPKz5nYNkzc9syw48MnUrSTPAddFIRll0qwrJLRVh2qQjLLhVh2aUi/HRZzRy/OXYyPLJLRVh2qQjLLhVh2aUiLLtUhGWXinDqTauKU2uj88guFWHZpSIsu1SEZZeKsOxSEZZdKsKptxE5BaTVxiO7VIRll4qw7FIRll0qwrJLRVh2qYiBZY+ITRHxXEQcioiDEXFXM74uIp6NiNean2snH1fSqIY5sn8AfDszrwS+CHwrIq4E7gH2ZOYVwJ7mvqQZNbDsmbmYmS83y+8Ah4GNwFZgV/OwXcDNkwopaXxndc0eEZcBVwMvAOszc7FZ9RawvtVkklo1dNkj4mLgceDuzHy7d11mJpArPG8hIvZGxN73eXessJJGN1TZI2KOpaI/mplPNMPHI2JDs34DcGK552bmjsycz8z5Oda0kVnSCIZ5NT6AR4DDmflgz6rdwPZmeTvwVPvxJLVlmL96+zJwG/BKRJz+oq17gfuBn0bE7cCbwK2TiSipDQPLnpm/BGKF1de1G0fSpPgOOqkIyy4VYdmlIiy7VIRll4qw7FIRll0qwrJLRVh2qQjLLhVh2aUiLLtUhGWXirDsUhGWXSrCsktFWHapCMsuFWHZpSIsu1SEZZeKsOxSEZZdKsKyS0VYdqkIyy4VYdmlIob5FtdNEfFcRByKiIMRcVczfl9EHIuIfc3tpsnHlTSqYb7F9QPg25n5ckRcArwUEc82676Xmd+dXDzp3PXVT26e6vaG+RbXRWCxWX4nIg4DGycdTFK7zuqaPSIuA64GXmiG7oyI/RGxMyLWtpxNUouGLntEXAw8DtydmW8DDwGXA5tZOvI/sMLzFiJib0TsfZ93W4gsaRRDlT0i5lgq+qOZ+QRAZh7PzFOZ+SHwMLBluedm5o7MnM/M+TnWtJVb0lka5tX4AB4BDmfmgz3jG3oedgtwoP14ktoyzKvxXwZuA16JiH3N2L3AtojYDCRwBLhjIgkltWKYV+N/CcQyq55uP46kSfEddFIRll0qwrJLRVh2qQjLLhVh2aUihpln1xQ987t9gx+kVWPaf9nWj0d2qQjLLhVh2aUiLLtUhGWXirDsUhFOvc2YWZqq0bnFI7tUhGWXirDsUhGWXSrCsktFWHapCMsuFWHZpSIsu1SEZZeKsOxSEZZdKsKyS0VYdqmIyMzpbSzi98CbPUOXAn+YWoDBzNPfrOWB2cvUdZ5PZ+Y/LrdiqmX/u41H7M3M+c4CnME8/c1aHpi9TLOWp5en8VIRll0qouuy7+h4+2cyT3+zlgdmL9Os5fmrTq/ZJU1P10d2SVPSSdkj4saI+N+IeD0i7ukiwxl5jkTEKxGxLyL2dpRhZ0SciIgDPWPrIuLZiHit+bm24zz3RcSxZj/ti4ibpphnU0Q8FxGHIuJgRNzVjHeyj/rk6WwfDTL10/iIOA94FbgeOAq8CGzLzENTDfK3mY4A85nZ2fxoRPwT8CfgPzPzqmbs34GTmXl/85/i2sz81w7z3Af8KTO/O40MZ+TZAGzIzJcj4hLgJeBm4F/oYB/1yXMrHe2jQbo4sm8BXs/MNzLzPeDHwNYOcsyUzHweOHnG8FZgV7O8i6V/TF3m6UxmLmbmy83yO8BhYCMd7aM+eWZWF2XfCPy25/5Rut9JCfw8Il6KiIWOs/Ran5mLzfJbwPouwzTujIj9zWn+1C4rekXEZcDVwAvMwD46Iw/MwD5aji/QLbkmMz8P/DPwreYUdqbk0vVW11MnDwGXA5uBReCBaQeIiIuBx4G7M/Pt3nVd7KNl8nS+j1bSRdmPAZt67n+qGetMZh5rfp4AnmTpUmMWHG+uDU9fI57oMkxmHs/MU5n5IfAwU95PETHHUrEezcwnmuHO9tFyebreR/10UfYXgSsi4jMRcT7wdWB3BzkAiIiLmhdYiIiLgBuAA/2fNTW7ge3N8nbgqQ6znC7Tabcwxf0UEQE8AhzOzAd7VnWyj1bK0+U+Gigzp34DbmLpFfnfAP/WRYaeLJ8F/ru5HewqD/AYS6d977P0OsbtwMeBPcBrwC+AdR3n+SHwCrCfpZJtmGKea1g6Rd8P7GtuN3W1j/rk6WwfDbr5DjqpCF+gk4qw7FIRll0qwrJLRVh2qQjLLhVh2aUiLLtUxF8AzzGTEWz1A7gAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}